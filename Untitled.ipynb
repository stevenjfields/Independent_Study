{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec49fc7-eebc-4e75-a81a-24e9560e1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steven/Desktop/Programming/Independent_Study/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8f4cbf-b895-4551-bb31-c592cc172be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Analysis of Relative Gene Expression Data Usin...</td>\n",
       "      <td>The two most commonly used methods to analyze ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>Deeper neural networks are more difficult to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A short history ofSHELX</td>\n",
       "      <td>An account is given of the development of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basic local alignment search tool</td>\n",
       "      <td>A new approach to rapid sequence comparison, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Random forests are a combination of tree predi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Analysis of Relative Gene Expression Data Usin...   \n",
       "1           1       Deep Residual Learning for Image Recognition   \n",
       "2           2                            A short history ofSHELX   \n",
       "3           3                  Basic local alignment search tool   \n",
       "4           4                                                NaN   \n",
       "\n",
       "                                            abstract  \n",
       "0  The two most commonly used methods to analyze ...  \n",
       "1  Deeper neural networks are more difficult to t...  \n",
       "2  An account is given of the development of the ...  \n",
       "3  A new approach to rapid sequence comparison, b...  \n",
       "4  Random forests are a combination of tree predi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('examples.tsv', delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75e9cec-948b-421a-9ae8-b04b657d8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = list()\n",
    "for index, row in df.iterrows():\n",
    "    if row['title'] and row['abstract']:\n",
    "        sentences = re.split(r\"\\b[.!?;]\\s\", str(row['abstract']))\n",
    "        sentences = [sentence for sentence in sentences if len(sentence) > 0]\n",
    "        papers.append(\n",
    "            {\n",
    "                'title': row['title'],\n",
    "                'sentences': sentences\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636ff0eb-5541-435c-91ef-55c46cc274bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The two most commonly used methods to analyze data from real-time, quantitative PCR experiments are absolute quantification and relative quantification. Absolute quantification determines the input copy number, usually by relating the PCR signal to a standard curve. Relative quantification relates the PCR signal of the target transcript in a treatment group to that of another sample such as an untreated control. The 2 −ΔΔ C T method is a convenient way to analyze the relative changes in gene expression from real-time quantitative PCR experiments. The purpose of this report is to present the derivation, assumptions, and applications of the 2 −ΔΔ C T method. In addition, we present the derivation and applications of two variations of the 2 −ΔΔ C T method that may be useful in the analysis of real-time, quantitative PCR data. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c221305-932d-4905-92b6-530bae388185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'BEDTools: a flexible suite of utilities for comparing genomic features',\n",
       " 'sentences': ['Testing for correlations between different sets of genomic features is a fundamental task in genomics research',\n",
       "  'However, searching for overlaps between features with existing web-based methods is complicated by the massive datasets that are routinely produced with current sequencing technologies',\n",
       "  'Fast and flexible tools are therefore required to ask complex questions of these data in an efficient manner.This article introduces a new software suite for the comparison, manipulation and annotation of genomic features in Browser Extensible Data (BED) and General Feature Format (GFF) format',\n",
       "  'BEDTools also supports the comparison of sequence alignments in BAM format to both BED and GFF features',\n",
       "  'The tools are extremely efficient and allow the user to compare large datasets (e.g',\n",
       "  'next-generation sequencing data) with both public and custom genome annotation tracks',\n",
       "  'BEDTools can be combined with one another as well as with standard UNIX commands, thus facilitating routine genomics tasks as well as pipelines that can quickly answer intricate questions of large genomic datasets.BEDTools was written in C++. Source code and a comprehensive user manual are freely available at http://code.google.com/p/bedtoolsaaronquinlan@gmail.com',\n",
       "  'imh4y@virginia.eduSupplementary data are available at Bioinformatics online']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d39275d-54a9-4710-8594-ac65b4357e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91cc09bb-61fe-46ab-9f22-1bd8013aa0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "for paper in papers[:100]:\n",
    "    for sentence in paper['sentences']:\n",
    "        # encode each sentence and append to dictionary\n",
    "        new_tokens = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                           truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt')\n",
    "        tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "        tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "        \n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15b4b3-97bc-42ac-9577-3f8a5f47b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae368b6f-58d5-4b3c-9848-ee4c33c741d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b8761-fc17-4273-8b26-2138664fdb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
