{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36f2c2f-7aa7-4fbd-92f1-b83161f4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "import pandas as pd\n",
    "from cogdl.oag import oagbert\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87037365-307e-4574-a86d-ae28217a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = 2\n",
    "ignore_related = True\n",
    "ignore_referenced = False\n",
    "base_works_url = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a67f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    # Keeping track of some needed paper details\n",
    "    id: str\n",
    "    title: str\n",
    "    inverted_abstract: Dict[str, List[int]]\n",
    "    authors: List[str]\n",
    "    host_venue: str\n",
    "    affiliations: List[str]\n",
    "    concepts: List[str]\n",
    "    references: List[str]\n",
    "    related: List[str]\n",
    "\n",
    "    def get_abstract(self) -> str:\n",
    "        abstract = dict()\n",
    "        for k, v in self.inverted_abstract.items():\n",
    "            for i in v:\n",
    "                abstract[i] = k\n",
    "\n",
    "        final = \"\"\n",
    "        for i in sorted(abstract.keys()):\n",
    "            final += abstract[i] + \" \"\n",
    "        return final\n",
    "    \n",
    "    def fetch_references_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.references), 50):\n",
    "            queries.append('|'.join(self.references[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def fetch_related_queries(self):\n",
    "        # open alex only allows 50 OR joins per request\n",
    "        queries = list()\n",
    "        for i in range(0, len(self.related), 50):\n",
    "            queries.append('|'.join(self.related[i:i+50]))\n",
    "        return queries\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.title}\\n{self.get_abstract()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5213e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article(result):\n",
    "    work_id = result[\"id\"].split('/')[-1]\n",
    "    title = result[\"title\"]\n",
    "    inverted_abstract = result['abstract_inverted_index']\n",
    "    authors = [authorship['author']['display_name'] for authorship in result['authorships']]\n",
    "    host_venue = result['host_venue']['publisher']\n",
    "    institutions = list()\n",
    "\n",
    "    for authorship in result['authorships']:\n",
    "        for institution in authorship['institutions']: \n",
    "            if institution['display_name'] not in institutions:\n",
    "                institutions.append(institution['display_name'])\n",
    "\n",
    "    concepts = [concept['display_name'] for concept in result['concepts'] if float(concept['score']) > 0.5]\n",
    "    referenced_works = [work.split('/')[-1] for work in result['referenced_works']]\n",
    "    related_works = [work.split('/')[-1] for work in result['related_works']]\n",
    "\n",
    "    return Article(\n",
    "        work_id,\n",
    "        title if title else \"\",\n",
    "        inverted_abstract if inverted_abstract else {\"\": [0]},\n",
    "        authors,\n",
    "        host_venue if host_venue else \"\",\n",
    "        institutions,\n",
    "        concepts,\n",
    "        referenced_works,\n",
    "        related_works\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4acd78-69c6-4c12-b59f-7c23b14f07b5",
   "metadata": {},
   "source": [
    "# Search for Article Title\n",
    "Edit the title variable below to search for a paper. If not exact then returns 25 most relevant papers in the OpenAlex dataset. Select the paper in the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c333ad3f-a953-494e-a1de-1e3bde69c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4575523107483db939fc7f4d973f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Title: ', options=('Attention is All you Need', 'Attention Is All You Need', 'Channel Atâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Attention is all you need\"\n",
    "title = title.replace(\" \", \"%20\")\n",
    "req = requests.get(base_works_url+f\"?filter=title.search:{title}\")\n",
    "response = json.loads(req.content)\n",
    "\n",
    "relevant_titles = [result['title'] for result in response['results']]\n",
    "title_selector = widgets.Dropdown(\n",
    "    options=relevant_titles,\n",
    "    value=relevant_titles[0],\n",
    "    description=\"Title: \"\n",
    ")\n",
    "display(title_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d531b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Please select correct title above. If done, run all cells below this one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease select correct title above. If done, run all cells below this one.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Please select correct title above. If done, run all cells below this one."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Please select correct title above. If done, run all cells below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c0ca5f4-8341-4d93-be7b-685485140c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = relevant_titles.index(title_selector.value)\n",
    "papers = dict()\n",
    "root_id = response['results'][index]['id'].split('/')[-1]\n",
    "\n",
    "papers[root_id] = fetch_article(response['results'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60843a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_references = ignore_referenced != True\n",
    "use_related = ignore_related != True\n",
    "\n",
    "related_works: Dict[int, List[Article]] = {}\n",
    "\n",
    "def get_relevant_papers(current_depth: int, previous: List[Article]):\n",
    "    related_works[current_depth] = []\n",
    "    print(current_depth)\n",
    "    for parent in previous:\n",
    "        if use_references and len(parent.references) > 0:\n",
    "            for query in parent.fetch_references_queries():         \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "            \n",
    "        if (use_related and len(parent.related) > 0) or len(parent.references) == 0:\n",
    "            for query in parent.fetch_related_queries():  \n",
    "                req = requests.get(base_works_url + f'?filter=openalex_id:{query}')\n",
    "                res = json.loads(req.content)\n",
    "                for result in res[\"results\"]:\n",
    "                    paper_id = result['id'].split('/')[-1]\n",
    "                    if paper_id not in papers.keys():\n",
    "                        temp = fetch_article(result)\n",
    "                        papers[temp.id] = temp\n",
    "                        related_works[current_depth].append(temp)\n",
    "\n",
    "    if current_depth < max_depth:\n",
    "        get_relevant_papers(current_depth+1, related_works[current_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a10c6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "get_relevant_papers(1, [papers[root_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9f04e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = oagbert(\"oagbert-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee4469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./embeddings/\"):\n",
    "    os.mkdir(\"./embeddings/\")\n",
    "\n",
    "files = os.listdir(\"./embeddings/\")\n",
    "files = [file.split('.')[0] for file in files]\n",
    "\n",
    "for key in papers.keys():\n",
    "    if key not in files:\n",
    "        curr_paper = papers[key]\n",
    "        input_ids, input_masks, token_type_ids, masked_lm_labels, position_ids, position_ids_second, masked_positions, num_spans = model.build_inputs(\n",
    "            title=curr_paper.title, \n",
    "            abstract=curr_paper.get_abstract(), \n",
    "            venue=curr_paper.host_venue, \n",
    "            authors=curr_paper.authors, \n",
    "            concepts=curr_paper.concepts, \n",
    "            affiliations=curr_paper.affiliations\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = model.bert.forward(\n",
    "            input_ids=torch.LongTensor(input_ids).unsqueeze(0),\n",
    "            token_type_ids=torch.LongTensor(token_type_ids).unsqueeze(0),\n",
    "            attention_mask=torch.LongTensor(input_masks).unsqueeze(0),\n",
    "            output_all_encoded_layers=False,\n",
    "            checkpoint_activations=False,\n",
    "            position_ids=torch.LongTensor(position_ids).unsqueeze(0),\n",
    "            position_ids_second=torch.LongTensor(position_ids_second).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        torch.save(pooled_output, f\"./embeddings/{curr_paper.id}.pt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6af4ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_paper_embeddings = torch.load(f\"./embeddings/{root_id}.pt\")\n",
    "root_paper_embeddings = torch.nn.functional.normalize(root_paper_embeddings, p=2, dim=1)\n",
    "\n",
    "paper_keys = list(papers.keys())\n",
    "paper_keys.remove(root_id)\n",
    "\n",
    "cols = [\"id\", \"title\", \"score\"]\n",
    "similarities = pd.DataFrame(columns=cols)\n",
    "\n",
    "for key in paper_keys:\n",
    "    paper_embeddings = torch.load(f\"./embeddings/{key}.pt\")\n",
    "    paper_embeddings = torch.nn.functional.normalize(paper_embeddings, p=2, dim=1)\n",
    "    sim = torch.mm(root_paper_embeddings, paper_embeddings.transpose(0, 1))\n",
    "    results = {\n",
    "        \"id\": [key],\n",
    "        \"title\": [papers[key].title],\n",
    "        \"score\": [sim.detach().numpy()]\n",
    "    }\n",
    "\n",
    "    similarities = pd.concat([similarities, pd.DataFrame(results)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e052225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>W2136939460</td>\n",
       "      <td>LSTM can Solve Hard Long Time Lag Problems</td>\n",
       "      <td>[[0.6680576]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>W2015861736</td>\n",
       "      <td>Convolutional networks and applications in vision</td>\n",
       "      <td>[[0.66090643]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>W2164019165</td>\n",
       "      <td>Improving Word Representations via Global Cont...</td>\n",
       "      <td>[[0.62542415]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>W2962739339</td>\n",
       "      <td>Deep Contextualized Word Representations</td>\n",
       "      <td>[[0.61234534]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>W2402268235</td>\n",
       "      <td>LSTM neural networks for language modeling</td>\n",
       "      <td>[[0.61059386]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>W2978017171</td>\n",
       "      <td>DistilBERT, a distilled version of BERT: small...</td>\n",
       "      <td>[[0.60469294]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W1902237438</td>\n",
       "      <td>Effective Approaches to Attention-based Neural...</td>\n",
       "      <td>[[0.60294294]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2194775991</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>[[0.5975584]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>W2963918774</td>\n",
       "      <td>Supervised Learning of Universal Sentence Repr...</td>\n",
       "      <td>[[0.59685653]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>W2996428491</td>\n",
       "      <td>ALBERT: A Lite BERT for Self-supervised Learni...</td>\n",
       "      <td>[[0.5942767]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>W2169805405</td>\n",
       "      <td>Convolutional Networks Can Learn to Generate A...</td>\n",
       "      <td>[[0.5913088]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>W2964110616</td>\n",
       "      <td>Transformer-XL: Attentive Language Models beyo...</td>\n",
       "      <td>[[0.59073764]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>W2118090838</td>\n",
       "      <td>Bilingual Word Embeddings for Phrase-Based Mac...</td>\n",
       "      <td>[[0.58978367]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>W932413789</td>\n",
       "      <td>Decoding with Large-Scale Neural Language Mode...</td>\n",
       "      <td>[[0.57869095]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>W2184045248</td>\n",
       "      <td>Deep Neural Networks for Acoustic Modeling in ...</td>\n",
       "      <td>[[0.5734992]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>W1521539493</td>\n",
       "      <td>WordNet for Italian and its use for lexical di...</td>\n",
       "      <td>[[0.55906975]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>W2147800946</td>\n",
       "      <td>Backpropagation Applied to Handwritten Zip Cod...</td>\n",
       "      <td>[[0.5545638]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>W2005708641</td>\n",
       "      <td>Hybrid speech recognition with Deep Bidirectio...</td>\n",
       "      <td>[[0.5498087]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>W2072128103</td>\n",
       "      <td>Learning Deep Architectures for AI</td>\n",
       "      <td>[[0.548921]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>W2147768505</td>\n",
       "      <td>Context-Dependent Pre-Trained Deep Neural Netw...</td>\n",
       "      <td>[[0.5483469]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W2095705004</td>\n",
       "      <td>Dropout: a simple way to prevent neural networ...</td>\n",
       "      <td>[[0.54750276]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>W1904365287</td>\n",
       "      <td>Improving neural networks by preventing co-ada...</td>\n",
       "      <td>[[0.5465107]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>W2158535772</td>\n",
       "      <td>Exploiting Object Hierarchy: Combining Models ...</td>\n",
       "      <td>[[0.5419961]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>W2964091467</td>\n",
       "      <td>Ask me anything: dynamic memory networks for n...</td>\n",
       "      <td>[[0.5392165]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>W1938755728</td>\n",
       "      <td>Character-Aware Neural Language Models</td>\n",
       "      <td>[[0.5357218]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "241  W2136939460         LSTM can Solve Hard Long Time Lag Problems   \n",
       "134  W2015861736  Convolutional networks and applications in vision   \n",
       "100  W2164019165  Improving Word Representations via Global Cont...   \n",
       "12   W2962739339           Deep Contextualized Word Representations   \n",
       "237  W2402268235         LSTM neural networks for language modeling   \n",
       "298  W2978017171  DistilBERT, a distilled version of BERT: small...   \n",
       "14   W1902237438  Effective Approaches to Attention-based Neural...   \n",
       "0    W2194775991       Deep Residual Learning for Image Recognition   \n",
       "116  W2963918774  Supervised Learning of Universal Sentence Repr...   \n",
       "296  W2996428491  ALBERT: A Lite BERT for Self-supervised Learni...   \n",
       "141  W2169805405  Convolutional Networks Can Learn to Generate A...   \n",
       "297  W2964110616  Transformer-XL: Attentive Language Models beyo...   \n",
       "164  W2118090838  Bilingual Word Embeddings for Phrase-Based Mac...   \n",
       "169   W932413789  Decoding with Large-Scale Neural Language Mode...   \n",
       "238  W2184045248  Deep Neural Networks for Acoustic Modeling in ...   \n",
       "71   W1521539493  WordNet for Italian and its use for lexical di...   \n",
       "26   W2147800946  Backpropagation Applied to Handwritten Zip Cod...   \n",
       "175  W2005708641  Hybrid speech recognition with Deep Bidirectio...   \n",
       "90   W2072128103                 Learning Deep Architectures for AI   \n",
       "151  W2147768505  Context-Dependent Pre-Trained Deep Neural Netw...   \n",
       "10   W2095705004  Dropout: a simple way to prevent neural networ...   \n",
       "129  W1904365287  Improving neural networks by preventing co-ada...   \n",
       "70   W2158535772  Exploiting Object Hierarchy: Combining Models ...   \n",
       "229  W2964091467  Ask me anything: dynamic memory networks for n...   \n",
       "221  W1938755728             Character-Aware Neural Language Models   \n",
       "\n",
       "              score  \n",
       "241   [[0.6680576]]  \n",
       "134  [[0.66090643]]  \n",
       "100  [[0.62542415]]  \n",
       "12   [[0.61234534]]  \n",
       "237  [[0.61059386]]  \n",
       "298  [[0.60469294]]  \n",
       "14   [[0.60294294]]  \n",
       "0     [[0.5975584]]  \n",
       "116  [[0.59685653]]  \n",
       "296   [[0.5942767]]  \n",
       "141   [[0.5913088]]  \n",
       "297  [[0.59073764]]  \n",
       "164  [[0.58978367]]  \n",
       "169  [[0.57869095]]  \n",
       "238   [[0.5734992]]  \n",
       "71   [[0.55906975]]  \n",
       "26    [[0.5545638]]  \n",
       "175   [[0.5498087]]  \n",
       "90     [[0.548921]]  \n",
       "151   [[0.5483469]]  \n",
       "10   [[0.54750276]]  \n",
       "129   [[0.5465107]]  \n",
       "70    [[0.5419961]]  \n",
       "229   [[0.5392165]]  \n",
       "221   [[0.5357218]]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities.sort_values(by=\"score\", ascending=False).head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0f4927",
   "metadata": {},
   "source": [
    "# Print Root Paper Abstract and 5 most similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f80b726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2963403868: Attention is All you Need\n",
      "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1. \n"
     ]
    }
   ],
   "source": [
    "print(papers[root_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42ff32c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2136939460: LSTM can Solve Hard Long Time Lag Problems\n",
      "Standard recurrent nets cannot deal with long minimal time lags between relevant signals. Several recent NIPS papers propose alternative methods. We first show: problems used to promote various previous algorithms can be solved more quickly by random weight guessing than by the proposed algorithms. We then use LSTM, our own recent algorithm, to solve a hard problem that can neither be quickly solved by random search nor by any other recurrent net algorithm we are aware of. \n",
      "\n",
      "\n",
      "\n",
      "W2015861736: Convolutional networks and applications in vision\n",
      "Intelligent tasks, such as visual perception, auditory perception, and language understanding require the construction of good internal representations of the world (or features)? which must be invariant to irrelevant variations of the input while, preserving relevant information. A major question for Machine Learning is how to learn such good features automatically. Convolutional Networks (ConvNets) are a biologically-inspired trainable architecture that can learn invariant features. Each stage in a ConvNets is composed of a filter bank, some nonlinearities, and feature pooling layers. With multiple stages, a ConvNet can learn multi-level hierarchies of features. While ConvNets have been successfully deployed in many commercial applications from OCR to video surveillance, they require large amounts of labeled training samples. We describe new unsupervised learning algorithms, and new non-linear stages that allow ConvNets to be trained with very few labeled samples. Applications to visual object recognition and vision navigation for off-road mobile robots are described. \n",
      "\n",
      "\n",
      "\n",
      "W2164019165: Improving Word Representations via Global Context and Multiple Word Prototypes\n",
      "Unsupervised word representations are very useful in NLP tasks both as inputs to learning algorithms and as extra word features in NLP systems. However, most of these models are built with only local context and one representation per word. This is problematic because words are often polysemous and global context can also provide useful information for learning word meanings. We present a new neural network architecture which 1) learns word embeddings that better capture the semantics of words by incorporating both local and global document context, and 2) accounts for homonymy and polysemy by learning multiple embeddings per word. We introduce a new dataset with human judgments on pairs of words in sentential context, and evaluate our model on it, showing that our model outperforms competitive baselines and other neural language models. \n",
      "\n",
      "\n",
      "\n",
      "W2962739339: Deep Contextualized Word Representations\n",
      "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals. \n",
      "\n",
      "\n",
      "\n",
      "W2402268235: LSTM neural networks for language modeling\n",
      "Neural networks have become increasingly popular for the task of language modeling. Whereas feed-forward networks only exploit a fixed context length to predict the next word of a sequence, conceptually, standard recurrent neural networks can take into account all of the predecessor words. On the other hand, it is well known that recurrent networks are difficult to train and therefore are unlikely to show the full potential of recurrent models. These problems are addressed by a the Long Short-Term Memory neural network architecture. In this work, we analyze this type of network on an English and a large French language modeling task. Experiments show improvements of about 8 % relative in perplexity over standard recurrent neural network LMs. In addition, we gain considerable improvements in WER on top of a state-of-the-art speech recognition system. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = similarities.sort_values(by=\"score\", ascending=False).head(5)[\"id\"]\n",
    "for id in ids.values:\n",
    "    print(papers[id])\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6f02c4897e5a2f50ed3c5fec7e665ad608d4dc358906e6dd46ab054316280e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
