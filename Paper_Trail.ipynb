{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36f2c2f-7aa7-4fbd-92f1-b83161f4ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87037365-307e-4574-a86d-ae28217a6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_depth = 2\n",
    "ignore_related = False\n",
    "ignore_referenced = False\n",
    "base_works_url = \"https://api.openalex.org/works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a67f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    # Keeping track of some needed paper details\n",
    "    id: str\n",
    "    title: str\n",
    "    inverted_abstract: Dict[str, List[int]]\n",
    "    references: List[str]\n",
    "    related: List[str]\n",
    "\n",
    "    def get_abstract(self):\n",
    "        abstract = dict()\n",
    "        for k, v in self.inverted_abstract.items():\n",
    "            for i in v:\n",
    "                abstract[i] = k\n",
    "\n",
    "        final = \"\"\n",
    "        for i in sorted(abstract.keys()):\n",
    "            final += abstract[i] + \" \"\n",
    "        return final\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4acd78-69c6-4c12-b59f-7c23b14f07b5",
   "metadata": {},
   "source": [
    "# Search for Article Title\n",
    "Edit the title variable below to search for a paper. If not exact then returns 25 most relevant papers in the OpenAlex dataset. Select the paper in the dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c333ad3f-a953-494e-a1de-1e3bde69c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55e5591b9294752bb267664395b5a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Title: ', options=('Attention is All you Need', 'Attention Is All You Need', 'All That Gâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Attention is all\"\n",
    "title = title.replace(\" \", \"%20\")\n",
    "req = requests.get(base_works_url+f\"?filter=title.search:{title}\")\n",
    "response = json.loads(req.content)\n",
    "\n",
    "relevant_titles = [result['title'] for result in response['results']]\n",
    "title_selector = widgets.Dropdown(\n",
    "    options=relevant_titles,\n",
    "    value=relevant_titles[0],\n",
    "    description=\"Title: \"\n",
    ")\n",
    "display(title_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d531b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Please select correct title above. If done, run all cells below this one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPlease select correct title above. If done, run all cells below this one.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Please select correct title above. If done, run all cells below this one."
     ]
    }
   ],
   "source": [
    "raise Exception(\"Please select correct title above. If done, run all cells below this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5213e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article(work_id):\n",
    "    req = requests.get(base_works_url + '/' + work_id)\n",
    "    result = json.loads(req.content)\n",
    "    referenced_works = [work.split('/')[-1] for work in result['referenced_works']]\n",
    "    related_works = [work.split('/')[-1] for work in result['related_works']]\n",
    "\n",
    "    return Article(\n",
    "        id,\n",
    "        result['title'],\n",
    "        result['abstract_inverted_index'],\n",
    "        referenced_works,\n",
    "        related_works\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0ca5f4-8341-4d93-be7b-685485140c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = relevant_titles.index(title_selector.value)\n",
    "papers = dict()\n",
    "root_id = response['results'][index]['id'].split('/')[-1]\n",
    "\n",
    "papers[root_id] = fetch_article(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4aa88b2-2e95-42c7-ac30-1b8d0058bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W2963403868'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84362a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article(id='W2963403868', title='Attention is All you Need', inverted_abstract={'The': [0, 19], 'dominant': [1], 'sequence': [2], 'transduction': [3], 'models': [4, 23, 59], 'are': [5], 'based': [6, 41], 'on': [7, 52], 'complex': [8], 'recurrent': [9], 'orconvolutional': [10], 'neural': [11], 'networks': [12], 'in': [13], 'an': [14, 31], 'encoder': [15, 27], 'and': [16, 28, 49, 68], 'decoder': [17, 29], 'configuration.': [18], 'best': [20, 90], 'performing': [21], 'such': [22], 'also': [24], 'connect': [25], 'the': [26, 88, 102], 'through': [30], 'attentionm': [32], 'echanisms.': [33], 'We': [34], 'propose': [35], 'a': [36, 111], 'novel,': [37], 'simple': [38], 'network': [39], 'architecture': [40], 'solely': [42], 'onan': [43], 'attention': [44], 'mechanism,': [45], 'dispensing': [46], 'with': [47, 77, 105], 'recurrence': [48], 'convolutions': [50], 'entirely.Experiments': [51], 'two': [53], 'machine': [54], 'translation': [55], 'tasks': [56], 'show': [57], 'these': [58], 'to': [60], 'be': [61], 'superiorin': [62], 'quality': [63], 'while': [64], 'being': [65], 'more': [66], 'parallelizable': [67], 'requiring': [69], 'significantly': [70], 'less': [71], 'timeto': [72], 'train.': [73], 'Our': [74], 'single': [75], 'model': [76, 106], '165': [78], 'million': [79], 'parameters,': [80], 'achieves': [81], '27.5': [82], 'BLEU': [83, 112], 'onEnglish-to-German': [84], 'translation,': [85, 99], 'improving': [86], 'over': [87, 94], 'existing': [89], 'ensemble': [91], 'result': [92], 'by': [93, 107], '1': [95], 'BLEU.': [96], 'On': [97], 'English-to-French': [98], 'we': [100], 'outperform': [101], 'previoussingle': [103], 'state-of-the-art': [104], '0.7': [108], 'BLEU,': [109], 'achieving': [110], 'score': [113], 'of': [114], '41.1.': [115]}, references=[], related=['W1902237438', 'W2064675550', 'W2095705004', 'W2101105183', 'W2108598243', 'W2130942839', 'W2153579005', 'W2154652894', 'W2157331557', 'W2163605009', 'W2194775991', 'W2250539671', 'W2525778437', 'W2962739339', 'W2962784628', 'W2963341956', 'W2964121744', 'W2964308564', 'W2965373594', 'W2970597249'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['W2963403868']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60843a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_references = ignore_referenced != True\n",
    "use_related = ignore_related != True\n",
    "\n",
    "related_works: Dict[int, List[Article]] = {}\n",
    "\n",
    "def get_relevant_papers(current_depth: int, previous: List[Article]):\n",
    "    related_works[current_depth] = []\n",
    "    print(current_depth)\n",
    "    for parent in previous:\n",
    "        if use_references:\n",
    "            for paper in parent.references:\n",
    "                if paper not in papers.keys():\n",
    "                    temp = fetch_article(paper)\n",
    "                    papers.append(temp)\n",
    "                    related_works[current_depth].append(temp)\n",
    "            \n",
    "        if use_related:\n",
    "            for paper in parent.related:\n",
    "                if paper not in papers.keys():\n",
    "                    temp = fetch_article(paper)\n",
    "                    papers.append(temp)\n",
    "                    related_works[current_depth].append(temp)\n",
    "\n",
    "    if current_depth <= max_depth:\n",
    "        get_relevant_papers(current_depth+1, related_works[current_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c6066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6f02c4897e5a2f50ed3c5fec7e665ad608d4dc358906e6dd46ab054316280e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
